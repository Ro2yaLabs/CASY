{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\miniconda\\envs\\mahmoud\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "e:\\miniconda\\envs\\mahmoud\\Lib\\site-packages\\onnxruntime\\capi\\onnxruntime_validation.py:26: UserWarning: Unsupported Windows version (11). ONNX Runtime supports Windows 10 and above, only.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from docx import Document\n",
    "import chromadb\n",
    "from openai import OpenAI\n",
    "import elevenlabs\n",
    "import subprocess\n",
    "import os\n",
    "from typing import Iterator\n",
    "from random import randint\n",
    "\n",
    "from wav2lip_master import inference_yolo\n",
    "from dataclasses import dataclass\n",
    "from wav2lip_master import audio\n",
    "\n",
    "from pydub import AudioSegment\n",
    "from io import BytesIO\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image, ImageTk\n",
    "import tkinter as tk\n",
    "\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "from IPython.display import display\n",
    "\n",
    "import base64\n",
    "\n",
    "@dataclass\n",
    "class Args:\n",
    "    checkpoint_path = r\"E:\\chat\\wav2lip_master\\checkpoints\\wav2lip.pth\"\n",
    "    audio = r\"E:\\chat\\inputs\\ms.wav\"\n",
    "    face = r\"E:\\chat\\inputs\\salma720.mp4\"\n",
    "    outfile = r'E:\\chat\\outputs\\out.mp4'\n",
    "    frame_path = r\"E:\\chat\\frames\"\n",
    "    fps = 25\n",
    "    face_det_batch_size = 16\n",
    "    wav2lip_batch_size = 32\n",
    "    resize_factor = 1\n",
    "    crop = [0, -1, 0, -1]\n",
    "    box = [-1, -1, -1, -1]\n",
    "    rotate = False\n",
    "    nosmooth = False\n",
    "    save_frames = False\n",
    "    static = False\n",
    "    save_as_video = False\n",
    "    img_size = 96\n",
    "    pads = [0, 0, 0, 0]\n",
    "    mel_step_size = 16\n",
    "    device = \"cpu\"\n",
    "    \n",
    "    \n",
    "\n",
    "class Casy:\n",
    "    def __init__(self, file_path, i):\n",
    "\n",
    "        self.args = Args()\n",
    "\n",
    "        self.model_id = \"sentence-transformers/paraphrase-MiniLM-L3-v2\"\n",
    "\n",
    "        self.wav2lib_model = inference_yolo.load_model(self.args.checkpoint_path)\n",
    "        self.yolo_model = YOLO('wav2lip_master/yolo/best.pt')\n",
    "\n",
    "        self.dim = 384\n",
    "        self.file_path = file_path\n",
    "        chroma_client = chromadb.PersistentClient(path=f\"./dp/demo{i}\")\n",
    "        self.collection = chroma_client.get_or_create_collection(\n",
    "            name=\"book\",\n",
    "            metadata={\"hnsw:space\": \"cosine\"}\n",
    "        )\n",
    "        full_text = self.read_docx(self.file_path)\n",
    "        splitted_txt = self.splitter(full_text)\n",
    "        self.model = self._encode()\n",
    "        encoded_text = self.model.encode(splitted_txt, show_progress_bar=True).tolist()\n",
    "        ids = [str(i) for i in range(len(encoded_text))]\n",
    "        self.collection.upsert(\n",
    "            documents=splitted_txt,\n",
    "            embeddings=encoded_text,\n",
    "            ids=ids\n",
    "        )\n",
    "        self.system = \"\"\"\n",
    "                I'll provide you with a JSON object that contains a question and the context related to it:\n",
    "                {\"question\": the question, \"context\": the context}\n",
    "                Please generate the answer of the provided question based on the context above in just 40 words no more even if the answer is missing something.\n",
    "                \"\"\"\n",
    "        \n",
    "        api_key = \"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\"\n",
    "        elevenlabs.set_api_key(\"f8b8bd17f45040b85ee67d3d0c6f0b1d\")\n",
    "        gemini_api = \"AIzaSyADgF911apMWrew1bvsazxFZOyn5YROLfI\"\n",
    "        \n",
    "        self.client = OpenAI(api_key=api_key)\n",
    "\n",
    "        self.messages = [\n",
    "            {\"role\": \"system\", \"content\": self.system}, \n",
    "        ]\n",
    "\n",
    "    def run(self, question):\n",
    "        question_embed = self.model.encode(question)\n",
    "        results = self.collection.query(\n",
    "            query_embeddings=question_embed.tolist(),\n",
    "            n_results=3,  \n",
    "        )\n",
    "        top_paragraph = ' '.join([i for i in results['documents']][0])\n",
    "        prompt = '{\"question\": ' + question + ', \"context\": ' + top_paragraph + '}'\n",
    "\n",
    "        self.messages.append(\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        )\n",
    "        self.audio = b\"\"\n",
    "        self.out = cv2.VideoWriter(f\"temp/res1.avi\",\n",
    "                                        cv2.VideoWriter_fourcc(*'DIVX'), 25, (720, 720))\n",
    "        self.generate_audio(prompt, self.messages)\n",
    "        self.out.release()\n",
    "        \n",
    "        audio_segment = AudioSegment.from_file(BytesIO(self.audio), format=\"mp3\")\n",
    "        audio_segment_resampled = audio_segment.set_frame_rate(16000)\n",
    "        audio_segment_resampled.export('temp/res.wav', format=\"wav\")\n",
    "        \n",
    "        # -c:v copy -c:a aac -strict experimental -ar 16000 -shortest -q:v 1\n",
    "        command = 'ffmpeg -y -i {} -i {} -strict -2 -q:v 1 {}'.format('temp/res.wav', 'temp/res1.avi', 'temp/res.mp4')\n",
    "        subprocess.call(command, shell=False)\n",
    "        \n",
    "    def read_docx(self, file_path):\n",
    "        doc = Document(file_path)\n",
    "        full_text = []\n",
    "        for para in doc.paragraphs:\n",
    "            full_text.append(para.text)\n",
    "        full_text = '\\n'.join(full_text)\n",
    "\n",
    "        return full_text\n",
    "\n",
    "    def splitter(self, txt):\n",
    "        \n",
    "        chunk_size = 1000\n",
    "        chunk_overlap = 200\n",
    "\n",
    "        def length_function(text: str) -> int:\n",
    "            return len(text)\n",
    "\n",
    "        splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=chunk_size,\n",
    "            chunk_overlap=chunk_overlap,\n",
    "            length_function=length_function\n",
    "        )\n",
    "\n",
    "        return splitter.split_text(txt)\n",
    "    \n",
    "    def _encode(self):\n",
    "        return SentenceTransformer(self.model_id, device=self.args.device)\n",
    "    \n",
    "    def get_smoothened_boxes(self, boxes, T):\n",
    "        \"\"\"\n",
    "        Smooth the bounding boxes over a temporal window.\n",
    "        \"\"\"\n",
    "        for i in range(len(boxes)):\n",
    "            if i + T > len(boxes):\n",
    "                window = boxes[len(boxes) - T:]\n",
    "            else:\n",
    "                window = boxes[i : i + T]\n",
    "            boxes[i] = np.mean(window, axis=0)\n",
    "        return boxes\n",
    "\n",
    "    def face_detect(self, images, args):\n",
    "        \"\"\"\n",
    "        Detect faces in a batch of images using YOLO.\n",
    "        \"\"\"\n",
    "        batch_size = args.face_det_batch_size\n",
    "        # batch_size = 1\n",
    "        \n",
    "        while 1:\n",
    "            predictions = []\n",
    "            try:\n",
    "                for i in range(0, len(images), batch_size):\n",
    "                    results = self.yolo_model.predict(images[i:i + batch_size], verbose=False, device=self.args.device)\n",
    "                    try:\n",
    "                        # boxes = results[0].boxes.xyxy[0].tolist()\n",
    "                        boxes = results[0].boxes.cpu().xyxy[0].tolist()\n",
    "                        predictions.append(boxes)\n",
    "                    except Exception as e:\n",
    "                        cv2.imwrite(f\"temp/faulty_frame{randint(0, 10000)}.jpg\", images[0])\n",
    "                        print(\"face not detected\")\n",
    "                    \n",
    "            except RuntimeError:\n",
    "                if batch_size == 1: \n",
    "                    raise RuntimeError('Image too big to run face detection on GPU. Please use the --resize_factor argument')\n",
    "                batch_size //= 2\n",
    "                print('Recovering from OOM error; New batch size: {}'.format(batch_size))\n",
    "                continue\n",
    "            break\n",
    "\n",
    "        results = []\n",
    "        pady1, pady2, padx1, padx2 = args.pads\n",
    "        for rect, image in zip(predictions, images):\n",
    "            if rect is None:\n",
    "                cv2.imwrite('temp/faulty_frame.jpg', image) # check this frame where the face was not detected.\n",
    "                raise ValueError('Face not detected! Ensure the video contains a face in all the frames.')\n",
    "            \n",
    "            y1 = max(0, int(rect[1]) - pady1)\n",
    "            y2 = min(image.shape[0], int(rect[3]) + pady2)\n",
    "            x1 = max(0, int(rect[0]) - padx1)\n",
    "            x2 = min(image.shape[1], int(rect[2]) + padx2)\n",
    "            \n",
    "            results.append([x1, y1, x2, y2])\n",
    "\n",
    "        boxes = np.array(results)\n",
    "        if not args.nosmooth: \n",
    "            boxes = self.get_smoothened_boxes(boxes, T=5)\n",
    "        results = [[image[y1: y2, x1:x2], (y1, y2, x1, x2)] for image, (x1, y1, x2, y2) in zip(images, boxes)]\n",
    "\n",
    "        return results \n",
    "\n",
    "    def datagen(self, mels, args):\n",
    "        \"\"\"\n",
    "        Data generator for processing batches.\n",
    "        \"\"\"\n",
    "        img_batch, mel_batch, frame_batch, coords_batch = [], [], [], []\n",
    "\n",
    "        reader = self.read_frames()\n",
    "        t = []\n",
    "        prev = None\n",
    "        for i, m in enumerate(mels):\n",
    "            try:\n",
    "                frame_to_save = next(reader)\n",
    "            except StopIteration:\n",
    "                reader = self.read_frames()\n",
    "                frame_to_save = next(reader)\n",
    "            \n",
    "            try:\n",
    "                prev = self.face_detect([frame_to_save], args)[0]\n",
    "                face, coords = prev\n",
    "            except:\n",
    "                face, coords = prev\n",
    "\n",
    "            face = cv2.resize(face, (args.img_size, args.img_size))\n",
    "                \n",
    "            if i%10000 == 0:\n",
    "                cv2.imwrite(f\"test{i}.jpg\", face)\n",
    "\n",
    "            img_batch.append(face)\n",
    "            mel_batch.append(m)\n",
    "            frame_batch.append(frame_to_save)\n",
    "            coords_batch.append(coords)\n",
    "\n",
    "            if len(img_batch) >= args.wav2lip_batch_size:\n",
    "                img_batch, mel_batch = np.asarray(img_batch), np.asarray(mel_batch)\n",
    "\n",
    "                img_masked = img_batch.copy()\n",
    "                img_masked[:, args.img_size//2:] = 0\n",
    "\n",
    "                img_batch = np.concatenate((img_masked, img_batch), axis=3) / 255.\n",
    "                mel_batch = np.reshape(mel_batch, [len(mel_batch), mel_batch.shape[1], mel_batch.shape[2], 1])\n",
    "\n",
    "                yield img_batch, mel_batch, frame_batch, coords_batch\n",
    "                img_batch, mel_batch, frame_batch, coords_batch = [], [], [], []\n",
    "        \n",
    "        if len(img_batch) > 0:\n",
    "            img_batch, mel_batch = np.asarray(img_batch), np.asarray(mel_batch)\n",
    "\n",
    "            img_masked = img_batch.copy()\n",
    "            img_masked[:, args.img_size//2:] = 0\n",
    "\n",
    "            img_batch = np.concatenate((img_masked, img_batch), axis=3) / 255.\n",
    "            mel_batch = np.reshape(mel_batch, [len(mel_batch), mel_batch.shape[1], mel_batch.shape[2], 1])\n",
    "\n",
    "            yield img_batch, mel_batch, frame_batch, coords_batch\n",
    "\n",
    "    def read_frames(self):\n",
    "        \"\"\"\n",
    "        Read frames from a folder of image files.\n",
    "        \"\"\"\n",
    "        \n",
    "        image_files = [f for f in os.listdir(self.args.frame_path) if f.split('.')[-1].lower() in ['jpg', 'png', 'jpeg']]\n",
    "        image_files.sort()\n",
    "\n",
    "        for image_file in image_files:\n",
    "            image_path = os.path.join(self.args.frame_path, image_file)\n",
    "            frame = cv2.imread(image_path)\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            yield frame\n",
    "\n",
    "    def _get_apen_ai_answer(self, prompt, messages):\n",
    "        response = self.client.chat.completions.create(\n",
    "            model = \"gpt-3.5-turbo-1106\",\n",
    "            temperature= 0,\n",
    "            messages=messages,\n",
    "            stream=True\n",
    "        )\n",
    "        \n",
    "        for chunk in response:\n",
    "            txt = chunk.choices[0].delta.content\n",
    "            # print(txt, end=\"\")\n",
    "            \n",
    "            yield txt if txt != None else \"\"\n",
    "            \n",
    "    def stream(self, audio_stream: Iterator[bytes]) -> bytes:\n",
    "\n",
    "        mpv_command = [\"C:\\\\Program Files\\\\mpv\\\\mpv.exe\", \"--no-cache\", \"--no-terminal\", \"--\", \"fd://0\"]\n",
    "        mpv_process = subprocess.Popen(\n",
    "            mpv_command,\n",
    "            stdin=subprocess.PIPE,\n",
    "            stdout=subprocess.DEVNULL,\n",
    "            stderr=subprocess.DEVNULL,\n",
    "        )\n",
    "\n",
    "        audio = b\"\"\n",
    "\n",
    "        for chunk in audio_stream:\n",
    "            if chunk is not None:\n",
    "                mpv_process.stdin.write(chunk)  # type: ignore\n",
    "                mpv_process.stdin.flush()  # type: ignore\n",
    "                audio += chunk\n",
    "\n",
    "        if mpv_process.stdin:\n",
    "            mpv_process.stdin.close()\n",
    "        mpv_process.wait()\n",
    "\n",
    "        return audio\n",
    "    \n",
    "    def stream_video(self, video_stream: Iterator[bytes]) -> bytes:\n",
    "\n",
    "        # ffmpeg_command = [\n",
    "        #     'ffmpeg',\n",
    "        #     '-f', 'rawvideo',\n",
    "        #     '-pixel_format', 'bgr24',\n",
    "        #     '-video_size', '720x720',\n",
    "        #     '-i', '-',\n",
    "        #     '-f', 'mpegts',\n",
    "        #     '-codec:v', 'mpeg1video',\n",
    "        #     '-bf', '0',\n",
    "        #     '-'\n",
    "        # ]\n",
    "        # mpv_command = ['|', 'C:\\\\Program Files\\\\mpv\\\\mpv.exe', '--no-cache', '--no-terminal', '--', '-']\n",
    "\n",
    "        # Combine both commands (simplified for explanation; actual implementation may vary)\n",
    "        # process_command = ' '.join(ffmpeg_command + mpv_command)\n",
    "        # process = subprocess.Popen(process_command, stdin=subprocess.PIPE, shell=True)\n",
    "        mpv_command = [\"C:\\\\Program Files\\\\mpv\\\\mpv.exe\", \"--no-cache\", \"--no-terminal\", \"--demuxer=rawvideo\", \"--demuxer-rawvideo-w=720\", \"--demuxer-rawvideo-h=720\", \"--demuxer-rawvideo-fps=25\", \"--\", \"-\"]\n",
    "        # mpv_command = [\n",
    "        #     \"C:\\\\Program Files\\\\mpv\\\\mpv.exe\",\n",
    "        #     \"--no-cache\",\n",
    "        #     \"--no-terminal\",\n",
    "        #     \"temp/res.mp4\"  # Directly specify the video file path here\n",
    "        # ]\n",
    "        # # Replace WIDTH, HEIGHT, and FPS with actual values for your video\n",
    "        mpv_process = subprocess.Popen(\n",
    "            mpv_command,\n",
    "            stdin=subprocess.PIPE,\n",
    "            stdout=subprocess.DEVNULL,\n",
    "            stderr=subprocess.DEVNULL,\n",
    "        )\n",
    "\n",
    "        video = b\"\"\n",
    "\n",
    "        for chunk in video_stream:\n",
    "            if chunk is not None:\n",
    "                mpv_process.stdin.write(chunk)  # type: ignore\n",
    "                mpv_process.stdin.flush()  # type: ignore\n",
    "                video += chunk\n",
    "\n",
    "        if mpv_process.stdin:\n",
    "            mpv_process.stdin.close()\n",
    "        mpv_process.wait()\n",
    "\n",
    "        return video\n",
    "\n",
    "    def generate_audio(self, prompt, messages):\n",
    "        audio_bytes = elevenlabs.generate(text=self._get_apen_ai_answer(prompt, messages), voice=\"Charlotte\", model=\"eleven_monolingual_v1\", stream=True, )\n",
    "        video_bytes = self._process_video(audio_bytes)\n",
    "        # return\n",
    "        self.stream_frames(video_bytes)\n",
    "        # self.stream(audio_bytes)\n",
    "\n",
    "    def _process_video(self, audio_bytes):\n",
    "        \n",
    "        for chunk in audio_bytes:\n",
    "            if chunk is not None:\n",
    "                self.audio += chunk\n",
    "\n",
    "                audio_segment = AudioSegment.from_file(BytesIO(chunk), format=\"mp3\")\n",
    "                audio_segment.export('temp/temp.mp3', format=\"mp3\")\n",
    "                command = 'ffmpeg -y -i {} -strict -2 {}'.format('temp/temp.mp3', 'temp/temp.wav')\n",
    "                subprocess.call(command, shell=True)\n",
    "                audio_path = 'temp/temp.wav'\n",
    "                wav = audio.load_wav(audio_path, 16000)\n",
    "                mel = audio.melspectrogram(wav)\n",
    "\n",
    "                mel_chunks = []\n",
    "                mel_idx_multiplier = 80./self.args.fps \n",
    "                i = 0\n",
    "                while 1:\n",
    "                    start_idx = int(i * mel_idx_multiplier)\n",
    "                    if start_idx + self.args.mel_step_size > len(mel[0]):\n",
    "                        mel_chunks.append(mel[:, len(mel[0]) - self.args.mel_step_size:])\n",
    "                        break\n",
    "                    mel_chunks.append(mel[:, start_idx : start_idx + self.args.mel_step_size])\n",
    "                    i += 1\n",
    "                print(\"melchuncks: \", len(mel_chunks))\n",
    "                gen = self.datagen(mel_chunks, self.args)\n",
    "                byte_image = b\"\"\n",
    "                for i, (img_batch, mel_batch, frames, coords) in enumerate(gen):\n",
    "                    img_batch = torch.FloatTensor(np.transpose(img_batch, (0, 3, 1, 2))).to(self.args.device)\n",
    "                    mel_batch = torch.FloatTensor(np.transpose(mel_batch, (0, 3, 1, 2))).to(self.args.device)\n",
    "\n",
    "                    with torch.no_grad():\n",
    "                        try:\n",
    "                            pred = self.wav2lib_model(mel_batch, img_batch)\n",
    "                        except:\n",
    "                            # print(1)\n",
    "                            # f = cv2.imread(\"frames/0.jpg\")\n",
    "                            # self.out.write(f)\n",
    "                            continue\n",
    "\n",
    "                    pred = pred.cpu().numpy().transpose(0, 2, 3, 1) * 255.\n",
    "                    \n",
    "                    for p, f, c in zip(pred, frames, coords):\n",
    "                        y1, y2, x1, x2 = c\n",
    "                        p = cv2.resize(p.astype(np.uint8), (x2 - x1, y2 - y1))\n",
    "                        f[y1:y2, x1:x2] = p\n",
    "                        # self.out.write(f) \n",
    "\n",
    "                        frame_bytes = cv2.imencode('.jpg', f)[1].tobytes()\n",
    "\n",
    "                        yield frame_bytes\n",
    "                        # _, encoded_image = cv2.imencode('.png', f) \n",
    "                        # byte_image += encoded_image.tobytes()\n",
    "            else:\n",
    "                print(1)\n",
    "                f = cv2.imread(\"frames/0.jpg\")\n",
    "                frame_bytes = cv2.imencode('.jpg', f)[1].tobytes()\n",
    "                yield frame_bytes\n",
    "                # yield byte_image               \n",
    "                    \n",
    "    def stream_frames(self, frame_generator):\n",
    "       \n",
    "        for frame_bytes in frame_generator:\n",
    "            nparr = np.frombuffer(frame_bytes, np.uint8)\n",
    "            img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            self.out.write(img)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load checkpoint from: E:\\chat\\wav2lip_master\\checkpoints\\wav2lip.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 12/12 [00:02<00:00,  5.28it/s]\n"
     ]
    }
   ],
   "source": [
    "answer_me = Casy(\"Master Machine Learning Algorithms - Discover how they work by Jason Brownlee (z-lib.org).docx\", 44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43manswer_me\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mexplain linear regression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 115\u001b[0m, in \u001b[0;36mCasy.run\u001b[1;34m(self, question)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maudio \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mVideoWriter(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemp/res1.avi\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    114\u001b[0m                                 cv2\u001b[38;5;241m.\u001b[39mVideoWriter_fourcc(\u001b[38;5;241m*\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDIVX\u001b[39m\u001b[38;5;124m'\u001b[39m), \u001b[38;5;241m25\u001b[39m, (\u001b[38;5;241m720\u001b[39m, \u001b[38;5;241m720\u001b[39m))\n\u001b[1;32m--> 115\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_audio\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    118\u001b[0m audio_segment \u001b[38;5;241m=\u001b[39m AudioSegment\u001b[38;5;241m.\u001b[39mfrom_file(BytesIO(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maudio), \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmp3\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[1], line 374\u001b[0m, in \u001b[0;36mCasy.generate_audio\u001b[1;34m(self, prompt, messages)\u001b[0m\n\u001b[0;32m    372\u001b[0m video_bytes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_video(audio_bytes)\n\u001b[0;32m    373\u001b[0m \u001b[38;5;66;03m# return\u001b[39;00m\n\u001b[1;32m--> 374\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream_frames\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 439\u001b[0m, in \u001b[0;36mCasy.stream_frames\u001b[1;34m(self, frame_generator)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstream_frames\u001b[39m(\u001b[38;5;28mself\u001b[39m, frame_generator):\n\u001b[1;32m--> 439\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mframe_bytes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mframe_generator\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    440\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnparr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrombuffer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe_bytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muint8\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    441\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnparr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIMREAD_COLOR\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 379\u001b[0m, in \u001b[0;36mCasy._process_video\u001b[1;34m(self, audio_bytes)\u001b[0m\n\u001b[0;32m    377\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_process_video\u001b[39m(\u001b[38;5;28mself\u001b[39m, audio_bytes):\n\u001b[1;32m--> 379\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43maudio_bytes\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    380\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[0;32m    381\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maudio\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
      "File \u001b[1;32me:\\miniconda\\envs\\mahmoud\\Lib\\site-packages\\elevenlabs\\api\\tts.py:117\u001b[0m, in \u001b[0;36mTTS.generate_stream_input\u001b[1;34m(text, voice, model, api_key, output_format, latency)\u001b[0m\n\u001b[0;32m    114\u001b[0m websocket\u001b[38;5;241m.\u001b[39msend(BOS)\n\u001b[0;32m    116\u001b[0m \u001b[38;5;66;03m# Stream text chunks and receive audio\u001b[39;00m\n\u001b[1;32m--> 117\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtext_chunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtext_chunker\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtry_trigger_generation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    119\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwebsocket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\miniconda\\envs\\mahmoud\\Lib\\site-packages\\elevenlabs\\api\\tts.py:20\u001b[0m, in \u001b[0;36mtext_chunker\u001b[1;34m(chunks)\u001b[0m\n\u001b[0;32m     18\u001b[0m splitters \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m?\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m!\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m—\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m}\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     19\u001b[0m buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 20\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunks\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendswith\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplitters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendswith\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n",
      "Cell \u001b[1;32mIn[1], line 286\u001b[0m, in \u001b[0;36mCasy._get_apen_ai_answer\u001b[1;34m(self, prompt, messages)\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_apen_ai_answer\u001b[39m(\u001b[38;5;28mself\u001b[39m, prompt, messages):\n\u001b[1;32m--> 286\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    287\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-3.5-turbo-1106\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    288\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    289\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    293\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m response:\n\u001b[0;32m    294\u001b[0m         txt \u001b[38;5;241m=\u001b[39m chunk\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdelta\u001b[38;5;241m.\u001b[39mcontent\n",
      "File \u001b[1;32me:\\miniconda\\envs\\mahmoud\\Lib\\site-packages\\openai\\_utils\\_utils.py:275\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    273\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    274\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 275\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\miniconda\\envs\\mahmoud\\Lib\\site-packages\\openai\\resources\\chat\\completions.py:663\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, presence_penalty, response_format, seed, stop, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    611\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    612\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    613\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    661\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m    662\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m--> 663\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    664\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    665\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    666\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    667\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    668\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    669\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    670\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    671\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    680\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    681\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    682\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    683\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    684\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    685\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    686\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    687\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    688\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    689\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    690\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    691\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m    692\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    693\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    694\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    695\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    696\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\miniconda\\envs\\mahmoud\\Lib\\site-packages\\openai\\_base_client.py:1200\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1187\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1188\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1195\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1196\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1197\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1198\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1199\u001b[0m     )\n\u001b[1;32m-> 1200\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32me:\\miniconda\\envs\\mahmoud\\Lib\\site-packages\\openai\\_base_client.py:889\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    880\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[0;32m    881\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    882\u001b[0m     cast_to: Type[ResponseT],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    887\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    888\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m--> 889\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    890\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    891\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    892\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    893\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    894\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    895\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\miniconda\\envs\\mahmoud\\Lib\\site-packages\\openai\\_base_client.py:965\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    963\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[0;32m    964\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m--> 965\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    966\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    967\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    968\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    969\u001b[0m \u001b[43m        \u001b[49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    974\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[0;32m    975\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[0;32m    976\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[1;32me:\\miniconda\\envs\\mahmoud\\Lib\\site-packages\\openai\\_base_client.py:1013\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[1;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1009\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[0;32m   1010\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[0;32m   1011\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[1;32m-> 1013\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1014\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1015\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1016\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1017\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1018\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1019\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\miniconda\\envs\\mahmoud\\Lib\\site-packages\\openai\\_base_client.py:965\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    963\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[0;32m    964\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m--> 965\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    966\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    967\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    968\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    969\u001b[0m \u001b[43m        \u001b[49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    974\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[0;32m    975\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[0;32m    976\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[1;32me:\\miniconda\\envs\\mahmoud\\Lib\\site-packages\\openai\\_base_client.py:1013\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[1;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1009\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[0;32m   1010\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[0;32m   1011\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[1;32m-> 1013\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1014\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1015\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1016\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1017\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1018\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1019\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\miniconda\\envs\\mahmoud\\Lib\\site-packages\\openai\\_base_client.py:980\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    977\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m    979\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 980\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    982\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[0;32m    983\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m    984\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    987\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m    988\u001b[0m )\n",
      "\u001b[1;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
     ]
    }
   ],
   "source": [
    "answer_me.run(\"explain linear regression\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    txt = input(\"\")\n",
    "    \n",
    "    if txt == \"End Session\": break\n",
    "    answer_me.run(txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading video frames from start...\n"
     ]
    }
   ],
   "source": [
    "vidcap = cv2.VideoCapture(\"inputs/ms.mp4\")\n",
    "total_frames = int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "print('Reading video frames from start...')\n",
    "\n",
    "i = 0\n",
    "\n",
    "for frameNumber in range(total_frames):\n",
    "    _, frame = vidcap.read()\n",
    "\n",
    "    cv2.imwrite(f\"frames/{i}.jpg\", frame)\n",
    "\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mpv_command = [\n",
    "    \"C:\\\\Program Files\\\\mpv\\\\mpv.exe\",\n",
    "    \"--no-cache\",\n",
    "    \"--no-terminal\",\n",
    "    \"temp/res.mp4\"  # Directly specify the video file path here\n",
    "]\n",
    "# Replace WIDTH, HEIGHT, and FPS with actual values for your video\n",
    "mpv_process = subprocess.Popen(\n",
    "    mpv_command,\n",
    "    stdin=subprocess.PIPE,\n",
    "    stdout=subprocess.DEVNULL,\n",
    "    stderr=subprocess.DEVNULL,\n",
    ")\n",
    "\n",
    "# video = b\"\"\n",
    "\n",
    "# for chunk in video_stream:\n",
    "#     if chunk is not None:\n",
    "#         mpv_process.stdin.write(chunk)  # type: ignore\n",
    "#         mpv_process.stdin.flush()  # type: ignore\n",
    "#         video += chunk\n",
    "\n",
    "# if mpv_process.stdin:\n",
    "#     mpv_process.stdin.close()\n",
    "mpv_process.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "misallam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
