{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from docx import Document\n",
    "from langchain.vectorstores import Chroma\n",
    "from openai import OpenAI\n",
    "import elevenlabs\n",
    "import subprocess\n",
    "import os\n",
    "from typing import Iterator\n",
    "\n",
    "class Chat:\n",
    "    def __init__(self, file_path, i):\n",
    "        self.model_id = \"paraphrase-MiniLM-L3-v2\"\n",
    "        self.device = \"cpu\"\n",
    "        self.dim = 384\n",
    "        self.file_path = file_path\n",
    "        chroma_client = chromadb.PersistentClient(path=f\"./dp/demo{i}\")\n",
    "        self.collection = chroma_client.create_collection(\n",
    "            name=\"book\",\n",
    "            metadata={\"hnsw:space\": \"cosine\"}\n",
    "        )\n",
    "        full_text = self.read_docx(self.file_path)\n",
    "        splitted_txt = self.splitter(full_text)\n",
    "        self.model = self._encode()\n",
    "        encoded_text = self.model.encode(splitted_txt, show_progress_bar=True).tolist()\n",
    "        ids = [str(i) for i in range(len(encoded_text))]\n",
    "        self.collection.add(\n",
    "            documents=splitted_txt,\n",
    "            embeddings=encoded_text,\n",
    "            ids=ids\n",
    "        )\n",
    "        self.system = \"\"\"\n",
    "                I'll provide you with a JSON object that contains a question and the context related to it:\n",
    "                {\"question\": the question, \"context\": the context}\n",
    "                Please generate the answer of the provided question based on the context above.\n",
    "                \"\"\"\n",
    "        \n",
    "        api_key = \"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\"\n",
    "        elevenlabs.set_api_key(\"19971a4ea37210273ae9e3f5a76174db\")\n",
    "        \n",
    "        self.client = OpenAI(api_key=api_key)\n",
    "\n",
    "        self.messages = [\n",
    "            {\"role\": \"system\", \"content\": self.system},\n",
    "            \n",
    "        ]\n",
    "\n",
    "    def run(self, question):\n",
    "        question_embed = self.model.encode(question)\n",
    "        results = self.collection.query(\n",
    "            query_embeddings=question_embed.tolist(),\n",
    "            n_results=3,  \n",
    "        )\n",
    "        top_paragraph = ' '.join([i for i in results['documents']][0])\n",
    "        prompt = '{\"question\": ' + question + ', \"context\": ' + top_paragraph + '}'\n",
    "\n",
    "        self.messages.append(\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        )\n",
    "\n",
    "        return self.generate_audio(prompt, self.messages)\n",
    "\n",
    "    def read_docx(self, file_path):\n",
    "        doc = Document(file_path)\n",
    "        full_text = []\n",
    "        for para in doc.paragraphs:\n",
    "            full_text.append(para.text)\n",
    "        full_text = '\\n'.join(full_text)\n",
    "\n",
    "        return full_text\n",
    "\n",
    "    def splitter(self, txt):\n",
    "        \n",
    "        chunk_size = 1000\n",
    "        chunk_overlap = 200\n",
    "\n",
    "        def length_function(text: str) -> int:\n",
    "            return len(text)\n",
    "\n",
    "        splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=chunk_size,\n",
    "            chunk_overlap=chunk_overlap,\n",
    "            length_function=length_function\n",
    "        )\n",
    "\n",
    "        return splitter.split_text(txt)\n",
    "    \n",
    "    def _encode(self):\n",
    "        return SentenceTransformerEmbeddings(model_name=self.model_id, device=self.device)\n",
    "    \n",
    "    def _get_apen_ai_answer(self, prompt, messages):\n",
    "        response = self.client.chat.completions.create(\n",
    "            model = \"gpt-3.5-turbo-1106\",\n",
    "            temperature= 0,\n",
    "            messages=messages,\n",
    "            stream=True\n",
    "        )\n",
    "        \n",
    "        for chunk in response:\n",
    "            txt = chunk.choices[0].delta.content\n",
    "            print(txt, end=\"\")\n",
    "            \n",
    "            yield txt if txt != None else \"\"\n",
    "            \n",
    "    def stream(self, audio_stream: Iterator[bytes]) -> bytes:\n",
    "\n",
    "        mpv_command = [\"C:\\\\Program Files\\\\mpv\\\\mpv.exe\", \"--no-cache\", \"--no-terminal\", \"--\", \"fd://0\"]\n",
    "        mpv_process = subprocess.Popen(\n",
    "            mpv_command,\n",
    "            stdin=subprocess.PIPE,\n",
    "            stdout=subprocess.DEVNULL,\n",
    "            stderr=subprocess.DEVNULL,\n",
    "        )\n",
    "\n",
    "        audio = b\"\"\n",
    "\n",
    "        for chunk in audio_stream:\n",
    "            if chunk is not None:\n",
    "                mpv_process.stdin.write(chunk)  # type: ignore\n",
    "                mpv_process.stdin.flush()  # type: ignore\n",
    "                audio += chunk\n",
    "\n",
    "        if mpv_process.stdin:\n",
    "            mpv_process.stdin.close()\n",
    "        mpv_process.wait()\n",
    "\n",
    "        return audio\n",
    "\n",
    "    def generate_audio(self, prompt, messages):\n",
    "        generated_audio = elevenlabs.generate(text=self._get_apen_ai_answer(prompt, messages), voice=\"tsample\", model=\"eleven_monolingual_v1\", stream=True)\n",
    "        self.stream(generated_audio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 12/12 [00:02<00:00,  4.49it/s]\n"
     ]
    }
   ],
   "source": [
    "answer_me = Chat(\"Master Machine Learning Algorithms - Discover how they work by Jason Brownlee (z-lib.org).docx\", 44)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine learning refers to the process of teaching a computer system to make predictions or take actions based on data, without being explicitly programmed. It involves the learning of a target function from training data through inductive learning, which refers to learning general concepts from specific examples. This is different from deduction, which seeks to learn specific concepts from general rules. In the context of machine learning, data plays a crucial role, and it is important to understand and use the right terminology when discussing it.None"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    txt = input(\"\")\n",
    "    \n",
    "    if txt == \"End Session\": break\n",
    "    answer_me.run(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': '\\n                I\\'ll provide you with a JSON object that contains a question and the context related to it:\\n                {\"question\": the question, \"context\": the context}\\n                Please generate the answer of the provided question based on the context above.\\n                '},\n",
       " {'role': 'user',\n",
       "  'content': '{\"question\": what is machine learning?, \"context\": Generalization in Machine Learning\\nIn machine learning we describe the learning of the target function from training data as inductive learning. Induction refers to learning general concepts from specific examples which is exactly the problem that supervised machine learning problems aim to solve. This is different from deduction that is the other way around and seeks to learn specific concepts from general rules. Machine Learning Books\\nThis book contains everything that you need to get started with machine learning algorithms, but if you are like me, then you love books. There are many machine learning books available, but below are a small selection that I recommend as the next step.\\n\\n      An Introduction to Statistical Learning. Excellent coverage of machine learning algorithms from a statistical perspective. Recommended as the next step. http://amzn.to/1pgirl0\\n      Applied Predictive Modeling. An excellent introduction to predictive modeling with coverage of a large number of algorithms. This book is better for breadth rather than depth on any one algorithm.\\nhttp://amzn.to/1n5MSsq\\n      Artificial Intelligence: A Modern Approach. An excellent book on artificial intelli- gence in general, but the chapters on machine learning give a superb computer science perspective of the algorithms covered in this book.\\nhttp://amzn.to/1TGk1rr Summary\\nIt is time to finally understand machine learning. This book is your ticket to machine learning algorithms. Next up you will build a foundation to understand the underlying problem that all machine learning algorithms are trying to solve.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nPart II Background\\n\\n\\n\\n\\n\\n\\nChapter 2\\nHow To Talk About Data in Machine Learning\\n\\nData plays a big part in machine learning. It is important to understand and use the right terminology when talking about data. In this chapter you will discover exactly how to describe and talk about data in machine learning. After reading this chapter you will know:\\n      Standard data terminology used in general when talking about spreadsheets of data.\\n      Data terminology used in statistics and the statistical view of machine learning.\\n      Data terminology used in the computer science perspective of machine learning.\\nThis will greatly help you with understanding machine learning algorithms in general. Let’s get started.}'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_me.messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_me.run(\"Give me an example for a linear regression prediction using (x) and (y) values\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "misallam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
