{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from docx import Document\n",
    "import chromadb\n",
    "from openai import OpenAI\n",
    "\n",
    "class Chat:\n",
    "    def __init__(self, file_path):\n",
    "        self.model_id = \"sentence-transformers/paraphrase-MiniLM-L3-v2\"\n",
    "        self.device = \"cuda:0\"\n",
    "        self.dim = 384\n",
    "        self.file_path = file_path\n",
    "        chroma_client = chromadb.PersistentClient(path=\"./cto-demo_1\")\n",
    "        self.collection = chroma_client.create_collection(\n",
    "            name=\"book\",\n",
    "            metadata={\"hnsw:space\": \"cosine\"}\n",
    "        )\n",
    "        full_text = self.read_docx(self.file_path)\n",
    "        splitted_txt = self.splitter(full_text)\n",
    "        self.model = self._encode()\n",
    "        encoded_text = self.model.encode(splitted_txt, show_progress_bar=True).tolist()\n",
    "        ids = [str(i) for i in range(len(encoded_text))]\n",
    "        self.collection.add(\n",
    "            documents=splitted_txt,\n",
    "            embeddings=encoded_text,\n",
    "            ids=ids\n",
    "        )\n",
    "        self.system = \"\"\"\n",
    "                I'll provide you with a JSON object that contains a question and the context related to it:\n",
    "                {\"question\": the question, \"context\": the context}\n",
    "                Please generate the answer of the provided question based on the context above.\n",
    "                \"\"\"\n",
    "        api_key = \"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\"\n",
    "        self.client = OpenAI(api_key=api_key)\n",
    "\n",
    "    def run(self, question):\n",
    "        question_embed = self.model.encode(question)\n",
    "        results = self.collection.query(\n",
    "            query_embeddings=question_embed.tolist(),\n",
    "            n_results=3,  \n",
    "        )\n",
    "        top_paragraph = ' '.join([i for i in results['documents']][0])\n",
    "        prompt = '{\"question\": ' + question + ', \"context\": ' + top_paragraph + '}'\n",
    "\n",
    "        return self._get_apen_ai_answer(prompt)\n",
    "\n",
    "    def read_docx(self, file_path):\n",
    "        doc = Document(file_path)\n",
    "        full_text = []\n",
    "        for para in doc.paragraphs:\n",
    "            full_text.append(para.text)\n",
    "        full_text = '\\n'.join(full_text)\n",
    "\n",
    "        return full_text\n",
    "\n",
    "    def splitter(self, txt):\n",
    "        \n",
    "        chunk_size = 1000\n",
    "        chunk_overlap = 200\n",
    "\n",
    "        def length_function(text: str) -> int:\n",
    "            return len(text)\n",
    "\n",
    "        splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=chunk_size,\n",
    "            chunk_overlap=chunk_overlap,\n",
    "            length_function=length_function\n",
    "        )\n",
    "\n",
    "        return splitter.split_text(txt)\n",
    "\n",
    "    def brain_dataset(self, text, threshold=100, dataset_name=\"dataset\"):\n",
    "        cleaned_text = re.sub(r'[^a-zA-Z0-9.%\\s]', '', text)\n",
    "        info_list = list(set(cleaned_text.split(\"\\n\")))\n",
    "        info_list = [para for para in info_list if para.strip() != \"\"]\n",
    "\n",
    "        nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "        for i, text in enumerate(info_list):\n",
    "            if len(text.split()) > threshold:\n",
    "                doc = nlp(text)\n",
    "                paragraphs = [paragraph.text for paragraph in doc.sents]\n",
    "                info_list.pop(i)\n",
    "                info_list[i:i] = paragraphs\n",
    "                ner_results = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "\n",
    "        df = pd.DataFrame(info_list, columns=['paragraph_info'])\n",
    "        dataset = df.to_csv(f\"{dataset_name}.csv\", index=False)\n",
    "\n",
    "        return dataset, ner_results\n",
    "    \n",
    "    def _encode(self):\n",
    "        return SentenceTransformer(self.model_id, device=self.device)\n",
    "    \n",
    "    def _get_apen_ai_answer(self, prompt):\n",
    "        response = self.client.chat.completions.create(\n",
    "            model = \"gpt-3.5-turbo-1106\",\n",
    "            temperature= 0,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": self.system},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 12/12 [00:00<00:00, 26.93it/s]\n"
     ]
    }
   ],
   "source": [
    "answer_me = Chat(\"Master Machine Learning Algorithms - Discover how they work by Jason Brownlee (z-lib.org).docx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The main topic of the book is to teach machine learning algorithms from scratch, specifically focusing on the type of machine learning where models are built to make predictions on new data, known as predictive modeling. The book is intended for developers and does not assume a background in statistics, probability, linear algebra, or machine learning. It is recommended to read the book linearly from start to finish, working through the tutorials provided to gain a practical understanding of the concepts and algorithms described.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = answer_me.run(\"what is the main topic of the book?\")\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "misallam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
